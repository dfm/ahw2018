\documentclass[letterpaper,12pt,preprint]{hack_aastex}

\input{dfm_stylez}
\pagestyle{myheadings}
\markright{\textsf{\footnotesize %
                   IMPRS summer school /
                   2016 /
                   MCMC exercises by Dan Foreman-Mackey}}

% Single-spacing.
\def\baselinestretch{1.1}

\include{figures/numbers-mh}
\include{figures/numbers-emcee}

\newcommand{\question}{\emph}

\begin{document}

In this exercise session you will implement a simple Metropolis MCMC sampler
in your programming language of choice.
You will test this sampler on a simple toy problem~--~drawing samples from a
two-dimensional Gaussian~--~and then on two more realistic problems.
The exercises are designed to take longer than the allotted 45~minutes so
don't worry if you don't finish.
Hopefully people with all levels of experience will learn something!
If you have previous experience with MCMC and if you have already implemented
a Metropolis sampler, why don't you take this time to implement a more
sophisticated method (ensemble, Hamiltonian, nested, or otherwise), try out a
new programming language, or help out other students with less experience.

\paragraph{Toy problem: a two-dimensional Gaussian}

In the following section you will implement your own Metropolis MCMC sampler
and test it by drawing samples from a two-dimensional Gaussian but the first
step is to implement the probability distribution as a function that takes in
a two-dimensional vector $\theta$ and returns:
\begin{eqnarray}
\ln p(\theta) &=& -\frac{1}{2}\,\theta^\mathrm{T}\,\Sigma^{-1}\,\theta
    + \mathrm{constant}
\end{eqnarray}
where
\begin{eqnarray}
\Sigma &=& \left(\begin{array}{cc}
1.0 & -0.08 \\
-0.08 & 0.01 \\
\end{array}\right)
\end{eqnarray}
Note: you definitely want to compute $\ln p$ (not just $p$).
\question{Why?}

\question{To test your probability function, ensure that the difference
between the function evaluated at two (random) points in parameter space is
the same as what I get.}
For example, make sure that you find the following:
\begin{eqnarray}
\ln p([0.5, -0.1]^\mathrm{T}) - \ln p([-0.01, 0.3]^\mathrm{T}) &\equiv&
    11.80847\ldots \quad.
\end{eqnarray}
If you don't get this result on the first try, debug your function until you
do.

\paragraph{A homegrown Metropolis sampler}

In this section, you will implement a Metropolis MCMC sampler to draw samples
from the distribution defined in the previous section.
As a reminder, the steps in a Metropolis MCMC are described here in words:
\begin{enumerate}

\item Initialize the parameters as $\theta(t=0)$.

\item Propose an update $q = \theta(t) + \sigma\,\delta$ where $\sigma$ is a
tuning parameter and $\delta$ is drawn from a zero mean, unit variance
Gaussian. Alternatively, you can try updating $\theta$ only one dimension.

\item Compute the acceptance probability $r =
\mathrm{min}\left(1,\,\frac{p(q)}{p(\theta(t))}\right)$.

\item Draw $u$ from a uniform distribution between 0 and 1. If $u < r$, accept
the proposal and set $\theta(t+1) = q$ to the chain. Otherwise, reject the
proposal and set $\theta(t+1) = \theta(t)$. Append $\theta(t+1)$ to the chain.
\emph{Note: in every iteration of this procedure a new entry is added to the
chain~--~even if the sample isn't accepted!}

\item Go to step 2 and repeat.

\end{enumerate}
Here are some suggestions to keep in mind for your implementation:
\begin{itemize}

\item In this function, you should track the acceptance fraction.
Keep track of how many proposals you accept.

\item As mentioned above, don't compute or use $p(\theta)$ directly~--~you
should only ever use the logarithm of this function.

\item Your implementation must support parameter \emph{vectors}.
For this problem, we're working in 2-D but don't special case to that because
it might be necessary to be able to sample more parameters later.

\item Similarly, you should implement the sampler in such a way that it is
easy to swap out a different probability function. Most programming languages
allow you to pass function pointers so taking the log-probability function as
an argument is probably the best interface.

\item Finally, to start the sampler, you must choose an initial location in
parameter space. Don't hard-code this location~--~take it as an
argument~--~because we'll test different initialization methods later.

\end{itemize}
\question{Implement the Metropolis MCMC method as a function with a calling
sequence something like}
\begin{center}
\texttt{samples, acc\_frac = metropolis(log\_prob\_func, sigma, inital\_theta,
num\_steps)}
\end{center}
This function should return the chain of samples and the accumulated
acceptance fraction.


\paragraph{Testing, tuning, and convergence (aka time to break your sampler)}

MCMC methods are notoriously hard to test rigorously so instead you can just
test your implementation qualitatively for today.
To start, initialize at a reasonable location (\question{What is a good way to
choose this in general?}) and \question{run some chains and look at a few
diagnostics}
\begin{itemize}

\item What is the acceptance fraction? Is this unreasonably high or low?
Note: this is a very easy problem so the acceptance fraction will
probably be higher than you would get in any problem in The Real
World\textsuperscript{\textsf{TM}}.

\item Compute the sample mean and covariance matrix of the chain. Is this
close to what you would expect? What do you expect and why? What happens as
you run the chain for longer?

\item Plot the trace (value as a function of step number) for each parameter.
See Figure~\ref{fig:traces} for an example of what to expect.

\item Plot the scatterplot matrix or corner plot to visualize the covariances
in the problem.
In Python you can use
\textsf{corner.py}\footnote{\url{http://corner.readthedocs.io}} and other
plotting libraries probably have similar functionality but, otherwise, you can
just make a scatterplot of the chain values.
Figure~\ref{fig:corner} shows an example using \textsf{corner.py}.

\item Try changing $\sigma$ and your initialization and remake these plots to
see what happens.
What happens as you make $\sigma$ extremely large $10^4$ or small $10^{-4}$?
What happens if you move the initial guess far away from the peak of the
distribution?

\end{itemize}

As discussed in lecture, the best quantification of sampler performance is the
integrated autocorrelation time $\tau_\mathrm{int}$.\footnote{Note: there isn't
just \emph{one} autocorrelation time.
$\tau_\mathrm{int}$ will, in general, be different for every different
$f(\theta)$ in Equation~\ref{eq:integral}.}
This provides an estimate of the number of steps of MCMC required to obtain an
independent sample.
Since MCMC is used to compute integrals, an estimate of $\tau_\mathrm{int}$ is
required to compute the sampling uncertainty on the approximation
\begin{eqnarray}\label{eq:integral}
\int f(\theta)\,p(\theta)\,\mathrm{d}\theta &\approx&
    \frac{1}{N} \sum_{n=1}^N f(\theta^{(n)}) \quad
    \mathrm{where}\,\theta^{(n)} \sim p(\theta)
\end{eqnarray}
and the sampler that produces a chain with a smallest value of
$\tau_\mathrm{int}$ at fixed computational cost is the best.

\question{Write or find a function that computes the autocorrelation
function\footnote{If you write your own function, don't directly sum the
variance at each lag~--~this will be way too slow. Instead, you could try
using an FFT.} of a one-dimensional chain and compute this for a few choices
of $f(\theta)$.} Figure~\ref{fig:autocorr} gives a few suggestions for
functions to consider.
\question{Then, find or implement a function that estimates the integrated
autocorrelation time}:
\begin{eqnarray}
\tau_\mathrm{int,est} &\approx& C(0) + 2\,\sum_{\tau=1}^W C(\tau)
\end{eqnarray}
where $C(\tau)$ is the autocorrelation function and $W$ is a tuning parameter.
Note: autocorrelation time estimates are always very noisy and you need to run
a long chain to get a reliable estimate.
Furthermore, the choice of $W$ can be subtle. Try several values of $W$ or
read A.~Sokal's notes\footnote{See pages 15--16 of this note:
\url{http://www.stat.unc.edu/faculty/cji/Sokal.pdf}} on how to choose $W$ more
robustly.
If you are working in Python, \textsf{emcee}\footnote{Versions 2.2.x and
greater: \url{http://dan.iel.fm/emcee/current/api/\#autocorrelation-analysis}.}
includes an implementation of this method.

For $\sigma = 0.1$, I find integrated autocorrelation times of \taua~steps and
\taub~steps for $f(\theta)=\theta_1$ and $f(\theta)=\theta_2$ respectively.
\question{Do you find the same? If not, why not?
Try changing $\sigma$ to see how the autocorrelation function and times
change.
Can you find a better choice of $\sigma$? What if you use different values of
$\sigma$ for each parameter? How many tuning parameters are there in this
method?}

\textbf{Bonus:} Try running a different sampling algorithm on the same problem
and compare performance using an estimate of the autocorrelation time.
For example, without any tuning,
\textsf{emcee}\footnote{\url{http://dfm.io/emcee}} gets autocorrelation times
of about \etaua~steps for both $f(\theta)=\theta_1$ and $f(\theta)=\theta_2$.
Can you match that performance using Metropolis? What changes did you have to
make?

\ssfigure{figures/traces.pdf}{0.5}{%
The parameter traces for Metropolis MCMC sampling of a two-dimensional
Gaussian.
The plots show the parameter values as a function of step number in the chain.
To show the autocorrelation on this plot, I zoomed in to only show the first
few steps but the full chain used for the following figures had $4\times 10^5$
steps.
\label{fig:traces}}

\ssfigure{figures/corner.pdf}{0.5}{%
A scatterplot matrix or corner plot of the chain from Figure~\ref{fig:traces}.
The central panel shows the scatterplot of the parameter values from the chain
and the histograms show the corresponding projections.
The scatterplot shows the Monte Carlo estimate of the joint probability
density $p(\theta_1,\,\theta_2\,|\,\mathrm{data})$ and the histograms are
estimates of the marginalized probability densities
$p(\theta_1\,|\,\mathrm{data})$ and $p(\theta_2\,|\,\mathrm{data})$.
\label{fig:corner}}

\ssfigure{figures/autocorr.pdf}{0.5}{%
The autocorrelation function for chains of $\{f_k(\theta^{(n)})\}_{n=1}^N$ for
different choices of $f_k$.
Compare this to Figure~\ref{fig:traces} to see how the autocorrelation relates
to the chain behavior.
Why do the autocorrelation functions have different scales?
Is the sampler well tuned for $f(\theta) = \theta_1$?
\label{fig:autocorr}}

% \ssfigure{figures/ensemble.pdf}{0.5}{%
% The autocorrelation function.
% \label{fig:ensemble}}

\clearpage
\paragraph{A more realistic problem: fitting a line to data}

In this section, you will fit a line to the small data set plotted in
Figure~\ref{fig:data} and available online at
\url{https://github.com/dfm/imprs/blob/master/mcmc/data.txt}\footnote{In this
file, the columns are $x$, $y$, $\sigma_y$, and $\sigma_x$.}.
If you just have data points with Gaussian uncertainties and Gaussian or broad
priors, you probably shouldn't use MCMC (because the posterior can be sampled
analytically) so let's make it a little more interesting: there is an
intrinsic scatter in the relationship and there are uncertainties on the $x$
values.

We'll start by ignoring the $x$ uncertainties but including the intrinsic
scatter parameterized by the logarithm of the scatter $\ln s$.
In this case, the likelihood is:
\begin{eqnarray}
\ln p (y\,|\,m,\,b,\,\ln s) &=& -\frac{1}{2} \sum_{n=1}^N\left[
\left(\frac{y_n-m\,x_n-b}{\sigma^2 + s^2}\right)^2 + \ln(2\,\pi\,(\sigma^2 +
s^2))\right]
\end{eqnarray}
(this derivation is left as an exercise)
and a reasonable choice of ``uninformative'' prior is\footnote{See
J.~VanderPlas's blog for a discussion of this choice:
\url{http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/}.}:
\begin{eqnarray}
\ln p(m,\,b,\,\ln s) &\propto& -\frac{3}{2}\ln(1+b^2) + B(m,\,b,\,\ln s)
\end{eqnarray}
where $B(m,\,b,\,\ln s)$ is a finite constant when $m$, $b$, and $\ln s$ take
values in a ``reasonable range'' (How should you choose this in general?) and
$-\infty$ otherwise.

Implement this model in code and try sampling from it using the sampler that
you implemented previously or another package.
Make all the diagnostic plots from above but include one new plot: the
posterior predictive distribution (see Figure~\ref{fig:line1}).
To achieve this, plot the line predicted for a few samples randomly selected
from the chain on top of the observed data.

Finally, implement the full model where uncertainties in $x$ are also
included.
To do this, you will need to choose a prior on $x_\mathrm{true}$~--~maybe
something like $\mathcal{U}(0,\,10)$~--~and sample the 13-dimensional problem
instead of the 3-dimensional case from before.
Before starting on this, you should draw the graphical model and consult with
any other students who are working on this part.

\newpage

\ssfigure{figures/data.pdf}{0.5}{%
The black points with error bars show the simulated data used for this
experiment.
The blue line is the true underlying model that generated the data and the
orange line is what you get if you run linear least squares and ignore the
intrinsic scatter in the relation.
\label{fig:data}}

\ssfigure{figures/line1.pdf}{0.5}{%
Like Figure~\ref{fig:data} but the gray lines show the prediction for 24
random samples from the chain.
The uncertainty is larger than for the least squares result but the true model
is within the credible region.
\label{fig:line1}}

% \begin{multicols}{2}
% {\centering\bf REFERENCES\par}
% \vspace{0.2em}
% \begin{thebibliography}{}%
% \raggedright\raggedbottom\scriptsize\setlength{\parskip}{-0.5em}%


% \end{thebibliography}
% \end{multicols}

\end{document}
